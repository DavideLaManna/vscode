{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacchetti usati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Dict, Any, Optional, Set\n",
    "from pydantic.json import pydantic_encoder\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from groq import Groq\n",
    "from together import Together\n",
    "import numpy as np\n",
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "from openai import OpenAI\n",
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "from neo4j_graphrag.generation.prompts import RagTemplate\n",
    "\n",
    "togetherai = Together(api_key=os.getenv(\"TOGETHERAI_API_KEY\"))\n",
    "groq = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "# Initialize the OpenAIEmbeddings with the desired model\n",
    "load_dotenv()\n",
    "neo4j_uri = os.getenv(\"NEO4J_URI1\")\n",
    "neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD1\")\n",
    "gpt = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definizione del knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class for a graph node without \"confidence\" and \"reason\" fields\n",
    "class BaseNode(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the node\")\n",
    "    type: List[str] = Field(..., description=\"Type of the node\")\n",
    "    attributes: dict = Field(default_factory=dict, description=\"Node attributes\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<BaseNode name={self.name}, type={self.type}, attributes={self.attributes}>\\n\"\n",
    "\n",
    "# Base class for a graph edge without the \"attributes\" field\n",
    "class BaseEdge(BaseModel):\n",
    "    source: str = Field(..., description=\"Source node name\")\n",
    "    target: str = Field(..., description=\"Target node name\")\n",
    "    type: str = Field(..., description=\"Type of relationship\")\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<BaseEdge from={self.source} to={self.target}, type={self.type}>\\n\"\n",
    "\n",
    "# Class representing the entire knowledge graph\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    nodes: List[BaseNode] = Field(default_factory=list, description=\"List of nodes\")\n",
    "    edges: List[BaseEdge] = Field(default_factory=list, description=\"List of edges\")\n",
    "\n",
    "    def add_node(self, node: BaseNode):\n",
    "        self.nodes.append(node)\n",
    "\n",
    "    def add_edge(self, edge: BaseEdge):\n",
    "        self.edges.append(edge)\n",
    "        \n",
    "    def add_BaseNode(self, name: str, types: Union[str, List[str]], attributes: Optional[Dict[str, Any]] = None):\n",
    "        # Consistent handling of types\n",
    "        if isinstance(types, str):\n",
    "            types = [types]\n",
    "        \n",
    "        self.nodes.append(\n",
    "            BaseNode(\n",
    "                name=name,\n",
    "                type=types,\n",
    "                attributes=attributes or {}\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def add_BaseEdge(self, source: str, target: str, type: str):\n",
    "        self.edges.append(\n",
    "            BaseEdge(\n",
    "                source=source,\n",
    "                target=target,\n",
    "                type=type\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def load_from_dict(self, data: Dict[str, Any]):\n",
    "        \"\"\"Load knowledge graph data from a dictionary\"\"\"\n",
    "        # Expecting nodes data to use 'name', 'types' (or 'type') and 'attributes'\n",
    "        for node_data in data.get(\"nodes\", []):\n",
    "            # Handle both 'type' and 'types' fields for backward compatibility\n",
    "            node_types = node_data.get(\"types\", node_data.get(\"type\", []))\n",
    "            self.add_BaseNode(\n",
    "                name=node_data[\"name\"],\n",
    "                types=node_types,\n",
    "                attributes=node_data.get(\"attributes\", {})\n",
    "            )\n",
    "            \n",
    "        for edge_data in data.get(\"edges\", []):\n",
    "            self.add_BaseEdge(\n",
    "                source=edge_data[\"source\"],\n",
    "                target=edge_data[\"target\"],\n",
    "                type=edge_data[\"type\"]\n",
    "            )\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def get_BaseNode_by_name(self, node_name: str) -> Optional[BaseNode]:\n",
    "        \"\"\"Get a BaseNode by its name\"\"\"\n",
    "        for node in self.nodes:\n",
    "            if node.name == node_name:\n",
    "                return node\n",
    "        return None\n",
    "        \n",
    "    def get_BaseNodes_by_type(self, node_type: str) -> List[BaseNode]:\n",
    "        \"\"\"Get all BaseNodes that have the specified type\"\"\"\n",
    "        return [node for node in self.nodes if node_type in node.type]\n",
    "    \n",
    "    def get_BaseNodes_with_multiple_types(self) -> List[BaseNode]:\n",
    "        \"\"\"Get all BaseNodes that have multiple types\"\"\"\n",
    "        return [node for node in self.nodes if len(node.type) > 1]\n",
    "    \n",
    "    def add_type_to_BaseNode(self, node_name: str, new_type: str) -> bool:\n",
    "        \"\"\"Add a type to an existing BaseNode\"\"\"\n",
    "        node = self.get_BaseNode_by_name(node_name)\n",
    "        if node:\n",
    "            if new_type not in node.type:\n",
    "                node.type.append(new_type)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_all_BaseNode_types(self) -> Set[str]:\n",
    "        \"\"\"Get all unique BaseNode types in the knowledge graph\"\"\"\n",
    "        types_set = set()\n",
    "        for node in self.nodes:\n",
    "            types_set.update(node.type)\n",
    "        return types_set\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert the knowledge graph to a dictionary with consistent field names\"\"\"\n",
    "        return {\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"name\": node.name,\n",
    "                    \"type\": node.type,\n",
    "                    \"attributes\": node.attributes\n",
    "                }\n",
    "                for node in self.nodes\n",
    "            ],\n",
    "            \"edges\": [\n",
    "                {\n",
    "                    \"source\": edge.source,\n",
    "                    \"target\": edge.target,\n",
    "                    \"type\": edge.type\n",
    "                }\n",
    "                for edge in self.edges\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"Convert the knowledge graph to a JSON string\"\"\"\n",
    "        return json.dumps(self.to_dict(), default=pydantic_encoder, indent=2)\n",
    "\n",
    "# Example of loading a knowledge graph with a BaseNode having multiple types\n",
    "def example_knowledge_graph():\n",
    "    # Create a new knowledge graph\n",
    "    kg = KnowledgeGraph()\n",
    "    \n",
    "    # Add BaseNodes with multiple types\n",
    "    kg.add_BaseNode(\n",
    "        name=\"person1\",\n",
    "        types=[\"Person\", \"Author\"],\n",
    "        attributes={\"name\": \"Jane Doe\", \"age\": 35}\n",
    "    )\n",
    "    \n",
    "    kg.add_BaseNode(\n",
    "        name=\"book1\",\n",
    "        types=[\"Book\"],\n",
    "        attributes={\"title\": \"Graph Theory Applications\", \"year\": 2023}\n",
    "    )\n",
    "    \n",
    "    # Add an edge\n",
    "    kg.add_BaseEdge(\n",
    "        source=\"person1\",\n",
    "        target=\"book1\",\n",
    "        type=\"WROTE\"\n",
    "    )\n",
    "    \n",
    "    # You can also load from a dictionary (e.g., from JSON)\n",
    "    data = {\n",
    "        \"nodes\": [\n",
    "            {\n",
    "                \"name\": \"person2\",\n",
    "                \"types\": [\"Person\", \"Researcher\", \"Teacher\"],\n",
    "                \"attributes\": {\"name\": \"John Smith\", \"institution\": \"University XYZ\"}\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"paper1\",\n",
    "                \"types\": [\"Publication\"],\n",
    "                \"attributes\": {\"title\": \"New Methods in Knowledge Graphs\", \"year\": 2024}\n",
    "            }\n",
    "        ],\n",
    "        \"edges\": [\n",
    "            {\n",
    "                \"source\": \"person2\",\n",
    "                \"target\": \"paper1\",\n",
    "                \"type\": \"AUTHORED\"\n",
    "            },\n",
    "            {\n",
    "                \"source\": \"person1\",\n",
    "                \"target\": \"person2\",\n",
    "                \"type\": \"COLLABORATES_WITH\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Load the additional data\n",
    "    kg.load_from_dict(data)\n",
    "    \n",
    "    return kg\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create and populate knowledge graph\n",
    "    knowledge_graph = example_knowledge_graph()\n",
    "    \n",
    "    # Print the graph information\n",
    "    print(f\"Knowledge Graph has {len(knowledge_graph.nodes)} nodes and {len(knowledge_graph.edges)} edges\")\n",
    "    \n",
    "    # Find nodes with multiple types using the new method\n",
    "    multi_type_nodes = knowledge_graph.get_BaseNodes_with_multiple_types()\n",
    "    print(f\"\\nNodes with multiple types: {len(multi_type_nodes)}\")\n",
    "    \n",
    "    for node in multi_type_nodes:\n",
    "        print(f\"Node Name: {node.name}\")\n",
    "        print(f\"Types: {', '.join(node.type)}\")\n",
    "        print(f\"Attributes: {node.attributes}\\n\")\n",
    "    \n",
    "    # Add another type to an existing node\n",
    "    knowledge_graph.add_type_to_BaseNode(\"book1\", \"TextBook\")\n",
    "    print(\"\\nAfter adding 'TextBook' type to 'book1':\")\n",
    "    book_node = knowledge_graph.get_BaseNode_by_name(\"book1\")\n",
    "    print(f\"Node Name: {book_node.name}\")\n",
    "    print(f\"Types: {', '.join(book_node.type)}\")\n",
    "    \n",
    "    # Get all nodes of a specific type\n",
    "    researchers = knowledge_graph.get_BaseNodes_by_type(\"Researcher\")\n",
    "    print(f\"\\nResearchers in the knowledge graph: {len(researchers)}\")\n",
    "    for researcher in researchers:\n",
    "        print(f\"- {researcher.name}: {researcher.attributes.get('name', 'Unknown')}\")\n",
    "    \n",
    "    # Display all unique node types in the graph\n",
    "    all_types = knowledge_graph.get_all_BaseNode_types()\n",
    "    print(f\"\\nAll node types in the knowledge graph: {', '.join(sorted(all_types))}\")\n",
    "    \n",
    "    # Export to JSON with consistent field names\n",
    "    print(\"\\nJSON representation (excerpt):\")\n",
    "    json_str = knowledge_graph.to_json()\n",
    "    print(json_str[:300] + \"...\" if len(json_str) > 300 else json_str)\n",
    "         \n",
    "'''class FeatureNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"FeatureNode\", description=\"This node is used to store product technical and functional features data.\")\n",
    "    name: str = Field(..., description=\"Name of the feature.\")\n",
    "    value: Union[float, List[float]] = Field(..., description=\"Value of the feature. It could be a single value or a list two values representing a range\")\n",
    "    unit: str = Field(..., description=\"Unit of the feature value\")\n",
    "    condition: Optional[str] = Field(..., description=\"Condition of the feature\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class InterfaceNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"InterfaceNode\", description=\"This node is used to store product interfaces data\")\n",
    "    name: str = Field(..., description=\"Name of the interface\")\n",
    "    parameter_name: str = Field(..., description=\"Name of the parameter\")\n",
    "    parameter_value: Optional[Union[int, float, str, List[float]]] = Field(..., description=\"Value of the parameter\")\n",
    "    table: Optional[List[dict]] = Field(..., description=\"Table of the interface\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class InstallationNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"InstallationNode\", description=\"This node is used to store product installation data\")\n",
    "    installation_details: str = Field(..., description=\"Details of the installation\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class CertificationNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"CertificationNode\", description=\"This node is used to store product certification data\")\n",
    "    name: str = Field(..., description=\"Name of the certification\")\n",
    "    certification_number: str = Field(..., description=\"Certification number\")\n",
    "    standards: List[str] = Field(default_factory=list, description=\"List of standards associated with the certification\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class SafetyNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"SafetyNode\", description=\"This node is used to store product safety data\")\n",
    "    title: str = Field(..., description=\"Title of the safety parameter or section\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class SafetyParametersNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"SafetyParametersNode\", description=\"This node is used to store product safety parameters data\")\n",
    "    parameters: dict = Field(..., description=\"Table of safety parameters\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class OrderNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"OrderNode\", description=\"This node is used to store product order data\")\n",
    "    code: str = Field(..., description=\"Order code\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class StartUpNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"StartUpNode\", description=\"This node is used to store product startup data\")\n",
    "    procedure: str = Field(..., description=\"Procedure for starting up the product\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class FieldConnectionNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"FieldConnectionNode\", description=\"This node is used to store product field connection data\")\n",
    "    name: str = Field(..., description=\"Name of the field connection\")\n",
    "    type: str = Field(..., description=\"Type of the field connection\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class OperationModeNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"OperationModeNode\", description=\"This node is used to store product operation mode data\")\n",
    "    name: str = Field(..., description=\"Type of the operation mode\")\n",
    "    description: str = Field(..., description=\"Instructions for the operation mode\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "\n",
    "class ConfigurationModeNode(BaseNode, frozen=True):\n",
    "    label: str = Field(\"ConfigurationModeNode\", description=\"This node is used to store product configuration data\")\n",
    "    name: str = Field(..., description=\"Name of the configuration\")\n",
    "    instructions: str = Field(..., description=\"Instructions for the configuration mode\")\n",
    "    source_text: str = Field(..., description=\"text content from which node information is extracted\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserimento dei json nel knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knowledge_graph_from_folder(folder_path: str):\n",
    "    \"\"\"\n",
    "    Reads JSON files in the specified folder (and its subfolders) and builds a knowledge graph.\n",
    "    \n",
    "    For each JSON file:\n",
    "      - Derives the PDF base from the \"pdf_name\" field.\n",
    "      - Creates nodes for each section (sections with key != \"-1\") and a special root node for sections with key \"-1\".\n",
    "      - Ensures a product node exists (node id equals the PDF base).\n",
    "      - Adds bidirectional edges based on \"supersections\" references. When a section’s supersection is \"-1\",\n",
    "        edges are also added from the product node.\n",
    "      - Forces every edge originating from the root node to have type \"product\".\n",
    "    \n",
    "    Returns:\n",
    "        KnowledgeGraph: The constructed knowledge graph.\n",
    "    \"\"\"\n",
    "    kg = KnowledgeGraph()\n",
    "    nodes = {}\n",
    "\n",
    "    def convert_ref(ref):\n",
    "        try:\n",
    "            return int(ref)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "\n",
    "    def add_bidirectional_edge(source, target, title):\n",
    "        # Add edge from source to target and a reverse edge with modified type.\n",
    "        kg.add_edge(BaseEdge(source=source, target=target, type=f\"has {title}\"))\n",
    "        #kg.add_edge(BaseEdge(source=target, target=source, type=f\"{title} of\"))\n",
    "\n",
    "    for root_dir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith(\".json\"):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(root_dir, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Derive PDF base name\n",
    "            pdf_name_raw = data.get(\"pdf_name\", \"Unknown\")\n",
    "            pdf_base = pdf_name_raw.split(\"_ISM\")[0] if \"_ISM\" in pdf_name_raw else pdf_name_raw\n",
    "            pdf_base = pdf_base.replace(\"_EN\", \"\").replace(\"_R\", \"\")\n",
    "\n",
    "            product_node_id = pdf_base\n",
    "            root_node_id = f\"{pdf_base} root\"\n",
    "\n",
    "            # Create product node if not already present.\n",
    "            if product_node_id not in nodes:\n",
    "                product_node = BaseNode(name=product_node_id, type=[\"product\"], attributes={})\n",
    "                nodes[product_node_id] = product_node\n",
    "                kg.add_node(product_node)\n",
    "\n",
    "            sections = data.get(\"sections\", {})\n",
    "            file_node_map = {}\n",
    "\n",
    "            # Create nodes for sections.\n",
    "            for sec_key, sec_data in sections.items():\n",
    "                if sec_key == \"-1\":\n",
    "                    # Create the special root node.\n",
    "                    if root_node_id not in nodes:\n",
    "                        root_node = BaseNode(name=\"root\", type=[\"root\"], attributes={})\n",
    "                        nodes[root_node_id] = root_node\n",
    "                else:\n",
    "                    ref_int = convert_ref(sec_key)\n",
    "                    if ref_int is None:\n",
    "                        continue\n",
    "                    node_id = f\"{pdf_base}_{ref_int}\"\n",
    "                    file_node_map[ref_int] = node_id\n",
    "                    title = sec_data.get(\"title\", \"\").strip()\n",
    "                    node = BaseNode(\n",
    "                        name=f\"{pdf_base} {title}\",\n",
    "                        type=[title],\n",
    "                        attributes={k: sec_data[k] for k in (\"tables\", \"text\") if k in sec_data}\n",
    "                    )\n",
    "                    nodes[node_id] = node\n",
    "                    kg.add_node(node)\n",
    "\n",
    "            # Create edges based on \"supersections\".\n",
    "            for sec_key, sec_data in sections.items():\n",
    "                if sec_key == \"-1\":\n",
    "                    continue\n",
    "                ref_int = convert_ref(sec_key)\n",
    "                if ref_int is None:\n",
    "                    continue\n",
    "                source_node_id = f\"{pdf_base}_{ref_int}\"\n",
    "                title = nodes[source_node_id].type\n",
    "                for ref in sec_data.get(\"supersections\", []):\n",
    "                    z = convert_ref(ref)\n",
    "                    if z is None:\n",
    "                        continue\n",
    "                    # Determine the super node: -1 references the root node.\n",
    "                    if z != -1: \n",
    "                        add_bidirectional_edge(nodes[file_node_map.get(z, f\"{pdf_base}_{z}\")].name, nodes[source_node_id].name, title)\n",
    "                    # If the supersection is -1, also connect the product node.\n",
    "                    if z == -1:\n",
    "                        add_bidirectional_edge(nodes[product_node_id].name, nodes[source_node_id].name, title)\n",
    "            kg.add_edge(BaseEdge(source=\"root\", target=nodes[product_node_id].name, type=\"product\"))\n",
    "    kg.add_node(root_node)\n",
    "    for node in kg.nodes:\n",
    "        # Se il campo name è una stringa vuota (dopo aver rimosso gli spazi) lo sostituisce\n",
    "        if isinstance(node.name, str) and not node.name.strip():\n",
    "            node.name = \"empty name\"\n",
    "        \n",
    "        # Se il campo label (node.type) è una stringa vuota lo sostituisce\n",
    "        if isinstance(node.type, str) and not node.type.strip():\n",
    "            node.type = \"empty label\"\n",
    "\n",
    "    return kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = input(\"Enter the folder path (default: dataset/extraction_results_renamed/ISM): \").strip()\n",
    "    if not folder_path:\n",
    "        folder_path = \"dataset/prova\"\n",
    "    \n",
    "    graph = create_knowledge_graph_from_folder(folder_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta e stampa il numero totale di nodi\n",
    "print(\"Total nodes:\", len(graph.nodes))\n",
    "empty_nodes_count = 0\n",
    "\n",
    "print(\"Nodes:\")\n",
    "for node in graph.nodes:\n",
    "    # Estrai e pulisci i campi name e label\n",
    "    node_name_raw = node.name if hasattr(node, \"name\") else \"\"\n",
    "    node_label_raw = node.type if hasattr(node, \"type\") else \"\"\n",
    "    \n",
    "    node_name = node_name_raw.strip()\n",
    "    node_label = node_label_raw\n",
    "    \n",
    "    # Verifica se name o label sono vuoti\n",
    "    if node_name == \"\" or node_label == \"\":\n",
    "        empty_nodes_count += 1\n",
    "        if node_name == \"\":\n",
    "            node_name = \"empty name\"\n",
    "        if node_label == \"\":\n",
    "            node_label = \"empty label\"\n",
    "    \n",
    "\n",
    "# Stampa il numero di nodi vuoti\n",
    "print(\"Total empty nodes:\", empty_nodes_count)\n",
    "\n",
    "# Conta e stampa il numero totale di edge\n",
    "print(\"\\nTotal edges:\", len(graph.edges))\n",
    "print(\"Edges:\")\n",
    "for edge in graph.edges:\n",
    "    print(edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzione che carica un KG su neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_knowledge_graph_into_neo4j(kg: KnowledgeGraph,\n",
    "                                    uri: str = os.getenv(\"NEO4J_URI1\"),\n",
    "                                    user: str = os.getenv(\"NEO4J_USERNAME\"),\n",
    "                                    password: str = os.getenv(\"NEO4J_PASSWORD1\")):\n",
    "    \"\"\"\n",
    "    Carica i nodi e le relazioni di un'istanza di KnowledgeGraph in Neo4j\n",
    "    usando il driver ufficiale (neo4j.GraphDatabase).\n",
    "\n",
    "    Per ogni nodo:\n",
    "      - Crea un nodo con label corrispondente a node.type\n",
    "      - Setta name=node.name come proprietà e aggiunge gli attributes \n",
    "        (convertendo eventuali strutture complesse in stringhe JSON).\n",
    "\n",
    "    Per ogni edge:\n",
    "      - Crea una relazione con type = edge.type\n",
    "        partendo dal nodo con name=edge.source \n",
    "        verso il nodo con name=edge.target.\n",
    "    \"\"\"\n",
    "\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    # Funzione per eseguire le modifiche di schema\n",
    "    def drop_schema(tx):\n",
    "        constraints = tx.run(\"SHOW CONSTRAINTS\").data()\n",
    "        for c in constraints:\n",
    "            constraint_name = c.get(\"name\")\n",
    "            if constraint_name:\n",
    "                tx.run(f\"DROP CONSTRAINT {constraint_name} IF EXISTS\")\n",
    "        indexes = tx.run(\"SHOW INDEXES\").data()\n",
    "        for idx in indexes:\n",
    "            index_name = idx.get(\"name\")\n",
    "            if index_name:\n",
    "                tx.run(f\"DROP INDEX {index_name} IF EXISTS\")\n",
    "\n",
    "    # Funzione per eliminare i dati\n",
    "    def clear_data(tx):\n",
    "        tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "    def create_node(tx, label, node_name, properties):\n",
    "        # Usiamo MERGE per creare il nodo se non esiste e poi aggiorniamo le proprietà.\n",
    "        query = (\n",
    "            f\"MERGE (n:`{label}`:suca {{ name: $node_name }}) \"\n",
    "            \"SET n += $props\"\n",
    "        )\n",
    "        tx.run(query, node_name=node_name, props=properties)\n",
    "\n",
    "    def create_relationship(tx, source_id, rel_type, target_id):\n",
    "        query = (\n",
    "            \"MATCH (s {name: $source_id}), (t {name: $target_id}) \"\n",
    "            f\"MERGE (s)-[r:`{rel_type}`]->(t)\"\n",
    "        )\n",
    "        tx.run(query, source_id=source_id, target_id=target_id)\n",
    "\n",
    "    def create_inverse_relationship(tx):\n",
    "        query = (\n",
    "            \"MATCH (x)-[r]->(y) \"\n",
    "            \"WHERE type(r) STARTS WITH 'has ' \"\n",
    "            \"WITH x, y, substring(type(r), 4) AS s \"\n",
    "            \"CALL apoc.create.relationship(y, s + ' of', {}, x) YIELD rel \"\n",
    "            \"RETURN count(rel) AS numCreated\"\n",
    "        )\n",
    "        result = tx.run(query)\n",
    "        return result.single()[\"numCreated\"]\n",
    "\n",
    "    with driver.session() as session:\n",
    "        # 1) Eseguiamo le modifiche di schema in una transazione separata\n",
    "        session.execute_write(drop_schema)\n",
    "        # 2) Puliamo i dati in una transazione separata\n",
    "        session.execute_write(clear_data)\n",
    "\n",
    "        # Creazione di tutti i nodi\n",
    "        for node in kg.nodes:\n",
    "            cleaned_attrs = {}\n",
    "            for k, v in node.attributes.items():\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    cleaned_attrs[k] = json.dumps(v)\n",
    "                else:\n",
    "                    cleaned_attrs[k] = v\n",
    "\n",
    "            session.execute_write(create_node, node.type, node.name, cleaned_attrs)\n",
    "\n",
    "        # Creazione di tutte le relazioni\n",
    "        for edge in kg.edges:\n",
    "            session.execute_write(create_relationship, edge.source, edge.type, edge.target)\n",
    "\n",
    "        # Creazione delle relazioni inverse per quelle che iniziano per \"has \"\n",
    "        num_created = session.execute_write(create_inverse_relationship)\n",
    "        print(f\"{num_created} relazioni inverse create.\")\n",
    "\n",
    "    driver.close()\n",
    "    print(\"Caricamento completato!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzione che interroga il database tramite prompt e fornisce una risposta testuale da parte di un llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2) Function that asks an LLM to generate a Cypher query\n",
    "def generate_cypher_query_from_prompt(prompt: str,model: str = \"llama-3.3-70b-versatile\") -> str:\n",
    "    \"\"\"\n",
    "    Sends the prompt to an LLM (e.g., ChatGPT) and receives a Cypher query in response\n",
    "    that addresses the user's request.\n",
    "    \"\"\"\n",
    "    system_instruction = ('''\n",
    "        You are an assistant that transforms questions or commands into Cypher queries \n",
    "        for a Neo4j database. Generate ONLY the Cypher query, nothing else.\n",
    "        example:\n",
    "        // How many Articles are in the database?\n",
    "        MATCH (a:Article)\n",
    "        RETURN COUNT(DISTINCT a) AS articleCount\n",
    "\n",
    "        // What are some example Articles in the database (without the embedding field)?\n",
    "        MATCH (a:Article)\n",
    "        RETURN apoc.map.removeKey(a, 'embedding') AS article\n",
    "        LIMIT 5\n",
    "\n",
    "        // What is the most commonly purchased Article?\n",
    "        MATCH (c:Customer)-[r:PURCHASED]->(a:Article)\n",
    "        RETURN a.prodName AS product, count(r) AS purchases\n",
    "        ORDER BY purchases DESC\n",
    "        LIMIT 5\n",
    "\n",
    "        // What Department has the most purchases?\n",
    "        MATCH (c:Customer)-[r:PURCHASED]->(:Article)-[:FROM_DEPARTMENT]->(d:Department)\n",
    "        RETURN d.departmentName AS department, count(r) AS purchases\n",
    "        ORDER BY purchases DESC\n",
    "        LIMIT 5'''\n",
    "    )\n",
    "    user_message = f\"User: {prompt}\\nGenerate the corresponding Cypher query (without the embedding field).\"\n",
    "    response = groq.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_instruction},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        temperature=0,  # Lower = more deterministic\n",
    "        stream=False,\n",
    "    )\n",
    "    generated_text = response.choices[0].message.content.strip()\n",
    "    return generated_text\n",
    "\n",
    "# New function: responds to the user using the context composed of:\n",
    "# - the user's prompt\n",
    "# - the generated Cypher query\n",
    "# - the database query results\n",
    "def answer_using_query_results(user_prompt: str, cypher_query: str, query_results: list,model: str = \"llama-3.3-70b-versatile\") -> str:\n",
    "    \"\"\"\n",
    "    Uses the user prompt, the generated Cypher query, and the query results as context\n",
    "    to generate an accurate and clear response for the user.\n",
    "    \"\"\"\n",
    "    system_instruction = (\n",
    "        \"You are an assistant that uses the provided context (user prompt, Cypher query, and query results) \"\n",
    "        \"to respond accurately and clearly to the user's question.\"\n",
    "    )\n",
    "    context = (\n",
    "        f\"User Prompt: {user_prompt}\\n\"\n",
    "        f\"Generated Cypher Query: {cypher_query}\\n\"\n",
    "        f\"Database Results: {query_results}\"\n",
    "    )\n",
    "    user_message = (\n",
    "        f\"Use the following context to answer the user's question:\\n\\n{context}\"\n",
    "    )\n",
    "    response = groq.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_instruction},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        temperature=0,  # deterministic\n",
    "        stream=False,\n",
    "    )\n",
    "    answer_text = response.choices[0].message.content.strip()\n",
    "    return answer_text\n",
    "\n",
    "# 3) Function that executes the generated Cypher query on Neo4j and returns the results\n",
    "def run_cypher_query_on_neo4j(query: str, uri: str = os.getenv(\"NEO4J_URI1\"), user: str = os.getenv(\"NEO4J_USERNAME\"), password: str = os.getenv(\"NEO4J_PASSWORD1\")):\n",
    "    \"\"\"\n",
    "    Executes the Cypher query on the Neo4j database, prints, and returns the results.\n",
    "    \"\"\"\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    results_list = []\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        for record in result:\n",
    "            results_list.append(dict(record))\n",
    "    driver.close()\n",
    "    print(\"Query Results:\")\n",
    "    for row in results_list:\n",
    "        print(row)\n",
    "    return results_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasformazione in attributi della parte testuale dei campi del KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_text(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Searches for a JSON dictionary within a text and returns it.\n",
    "    The JSON substring is extracted from the first '{' to the last '}'.\n",
    "    If no valid JSON is found, returns {}.\n",
    "    \"\"\"\n",
    "    # Find the index of the first '{' and the last '}'\n",
    "    start_index = text.find('{')\n",
    "    end_index = text.rfind('}')\n",
    "    \n",
    "    # Check if both braces were found and in correct order\n",
    "    if start_index == -1 or end_index == -1 or start_index > end_index:\n",
    "        return {}\n",
    "    \n",
    "    json_string = text[start_index:end_index+1]\n",
    "    \n",
    "    try:\n",
    "        parsed_json = json.loads(json_string)\n",
    "        if isinstance(parsed_json, dict):\n",
    "            return parsed_json\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    return {}\n",
    "\n",
    "def extract_scalar_features(text: str, model: str = \"llama-3.3-70b-versatile\", max_calls: int = 1) -> dict:\n",
    "    \"\"\"\n",
    "    Uses Groq to extract the main numerical or scalar features from the text,\n",
    "    returning them as a dictionary.\n",
    "    \n",
    "    If the returned JSON is empty, the LLM call is repeated up to a maximum of 'max_calls' times (default 10).\n",
    "    If after all calls a valid output is not obtained, returns {}.\n",
    "    \"\"\"\n",
    "    # System prompt: Instruisce il modello ad utilizzare un formato JSON specifico, con un esempio chiaro.\n",
    "    system_prompt = \"\"\" \n",
    "You are an assistant tasked with precisely and thoroughly extracting numerical, measurable, scalar values and their descriptions from provided product description text specifically for Relay Output Modules of Switch/Proximity Detector Repeaters.\n",
    "\n",
    "Your goal is to populate a structured JSON object intended to build a detailed knowledge graph. This structured data will represent attributes, specifications, characteristics, and certifications of relay output modules accurately and completely.  \n",
    "\n",
    "# Detailed Steps:\n",
    "\n",
    "1. **Carefully read the provided product text**.\n",
    "2. **Precisely identify and explicitly extract mentioned numerical values, scalar data, measurable values, and their units** from the following specific fields (ONLY if explicitly stated in the text):\n",
    "   - **Supply** (e.g., voltage information — ranges or single values; current specifications)\n",
    "   - **Isolation (Test Voltage)** (explicit numeric voltage and values)\n",
    "   - **Input** (signals, ranges, voltage, current, frequency, or other numeric specifics related directly to the input)\n",
    "   - **Output** (output voltage, current, power ratings explicitly mentioned)\n",
    "   - **Compatibility** (specified numeric standards or numerical descriptions explicitly mentioned)\n",
    "   - **Environmental Conditions** (temperature ranges, humidity, altitude explicitly numerical)\n",
    "   - **Safety descriptions** (numbers related to safety specifications explicitly stated in the text)\n",
    "   - **Approvals** (numerical certificates, classes, groups, or numeric standard numbers)\n",
    "   - **Mounting** (specific numeric mounting dimensions or numerical descriptors clearly defined in the text)\n",
    "3. **Do not create empty fields whatsoever**. If a field or numeric measurement is not explicitly stated, completely omit this information.\n",
    "4. If a numerical specification is a range, store it explicitly as an array of numbers: `[min, max]`.\n",
    "5. **Include all numeric values without altering them. Do not estimate, infer, guess, or round numeric values. Keep exact numbers as explicitly mentioned.**\n",
    "6. **Include units of measurement exactly as explicitly given in the provided input text.**\n",
    "7. **If a numeric field has no stated unit of measure, DO NOT include a unit.**\n",
    "8. For product dimension information explicitly stated in the text, aggregate this information into a single array `[Width, Height, Depth]` with stated units where explicitly provided.\n",
    "9. Provide a detailed, textual description.  \n",
    "   - Summarize briefly and clearly based on the provided source text.  \n",
    "   - If uncertain on how best to summarize and to prevent empty descriptions, copy text directly as the description in full as last resort.  \n",
    "   - NEVER leave the description field blank.\n",
    "\n",
    "# Output Format:\n",
    "\n",
    "Produce a structured JSON object similar to the following schema !Attention, except for the description, the other fields may be different!:\n",
    "\n",
    "{\n",
    "  \"description\": \"textual description of around 70% total lenght of the text taken from the source text explicitly\",\n",
    "  \"supply\": {\n",
    "      \"voltage\": { \"range\": [X, Y], \"unit\": \"[explicit unit from text]\" } OR { \"value\": X, \"unit\": \"[explicit unit from text]\" },\n",
    "      \"current\": { \"range\": [X, Y], \"unit\": \"[explicit unit from text]\" } OR { \"value\": X, \"unit\": \"[explicit unit from text]\" } (only if explicitly stated)\n",
    "  }, (only present if explicitly stated)\n",
    "  \"isolation\": {\n",
    "      \"test_voltage\": { \"value\": X, \"unit\": \"[explicit unit from text]\" }\n",
    "  }, (only present if explicitly stated)\n",
    "  \"input\": {\n",
    "      \"[attribute_name]\": { \"range\": [X, Y], \"unit\": \"[explicit unit from text]\" } OR {\"value\": X, \"unit\": \"[explicit unit from text]\"}\n",
    "  }, (only present if explicitly stated)\n",
    "  \"output\": {\n",
    "      \"[attribute_name]\": { \"range\": [X, Y], \"unit\": \"[explicit unit from text]\" } OR {\"value\": X, \"unit\": \"[explicit unit from text]\"}\n",
    "  }, (only present if explicitly stated)\n",
    "  \"compatibility\": [\"[explicit numerical or scalar compatibility specifications from text]\"], (only present if explicitly stated explicitly numerically or scalar)\n",
    "  \"environmental_conditions\": {\n",
    "      \"temperature\": { \"range\": [X, Y], \"unit\": \"[explicit unit from text]\" },\n",
    "      \"humidity\": { \"range\": [X, Y], \"unit\": \"[explicit unit from text]\" },\n",
    "      \"altitude\": { \"value\": X, \"unit\": \"[explicit unit from text]\" }\n",
    "  }, (only present if explicitly stated)\n",
    "  \"safety\": {\n",
    "      \"[attribute_name (e.g. protection_rating)]\": { \"value\": X, \"unit\": \"[explicit unit from text, unless unspecified explicitly]\" }\n",
    "  }, (only present if explicitly stated)\n",
    "  \"approvals\": [\"[explicit numeric approval or certification identifiers if explicitly stated]\"], (only present if explicitly stated)\n",
    "  \"mounting\": {\n",
    "      \"[numeric attribute_name (e.g. dimensions)]\": { \"value\": [X, Y, Z], \"unit\":\"[explicit unit from text]\" } OR numeric_scalar_values explicitly mentioned\n",
    "  } (only present if explicitly stated)\n",
    "}\n",
    "\n",
    "If certain fields as listed above appear nowhere explicitly in the source text, entirely omit them from your final output. Do NOT generate empty or speculative fields; **ONLY input factual numerically-expressed data provided explicitly.**\n",
    "\n",
    "# Examples:\n",
    "\n",
    "Begin Examples:\n",
    "\n",
    "Input:\n",
    "\"The Relay Module has a supply voltage ranging from 110V to 240V and current consumption of 500mA. Isolation is tested with 2500 V. Input frequency is between 50Hz and 60Hz. The output relay supports up to 10A at 250VAC. Operating temperature range specified is -20°C to 60°C. The relay module carries ATEX approval numbers 0073 II (1) G Ex ia IIC. Dimensions are width 50mm, height 70mm, and depth 25mm.\"\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"description\": \"Relay Module with specified voltage, current, isolation, input frequency, output current rating, temperature range, approvals and dimensions.\",\n",
    "  \"supply\": {\n",
    "      \"voltage\": {\"range\": [110, 240], \"unit\":\"V\"},\n",
    "      \"current\": {\"value\": 500, \"unit\":\"mA\"}\n",
    "  },\n",
    "  \"isolation\": {\n",
    "      \"test_voltage\": {\"value\":2500, \"unit\":\"V\"}\n",
    "  },\n",
    "  \"input\": {\n",
    "      \"frequency\": {\"range\": [50,60], \"unit\":\"Hz\"}\n",
    "  },\n",
    "  \"output\": {\n",
    "      \"current\": {\"value\":10, \"unit\":\"A\"},\n",
    "      \"voltage\": {\"value\":250, \"unit\":\"VAC\"}\n",
    "  },\n",
    "  \"environmental_conditions\": {\n",
    "      \"temperature\": {\"range\":[-20,60],\"unit\":\"°C\"}\n",
    "  },\n",
    "  \"approvals\": [\"0073 II (1) G Ex ia IIC\"],\n",
    "  \"mounting\": {\n",
    "      \"dimensions\": {\"value\":[50,70,25], \"unit\":\"mm\"}\n",
    "  }\n",
    "}\n",
    "input: \n",
    "\"The battery supports a charge voltage from 3.0V to 4.2V. It has a capacity of 5000mAh and weighs approximately 250 grams. The retail price is 29.99 euros.\",\n",
    "output:\n",
    "{\n",
    "    'description': 'The battery has specific charge voltage, capacity, weight, and retail price.',\n",
    "    \"charge_voltage\": {\"range\": [3.0, 4.2], \"unit\": \"V\"},\n",
    "    \"capacity\": {\"value\": 5000, \"unit\": \"mAh\"},\n",
    "    \"weight\": {\"value\": 250, \"unit\": \"g\"},\n",
    "    \"price\": {\"value\": 29.99, \"unit\": \"EUR\"}\n",
    "}\n",
    "\n",
    "End Examples.\n",
    "\n",
    "# Notes:\n",
    "- Do not hallucinate any numeric values or details. Strict adherence required.\n",
    "- Do NOT wrap returned JSON in code blocks (```) or any formatting unless explicitly requested.\n",
    "- Always keep the numerical values PRECISELY as provided.\n",
    "- Failure to follow instructions EXACTLY may result in critical system error and severe consequences.\n",
    "- The description field must contain all non-numeric information in the text\n",
    "    \"\"\"    \n",
    "    # User prompt: Include il testo di input e le istruzioni per restituire l'output esattamente nel formato richiesto.\n",
    "    user_prompt = \"\"\"\n",
    "    Extract all the numerical or scalar values from the following text and summarize the verbose parts in the `description` field.  \n",
    "    Text:  \n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    user_prompt = user_prompt.format(text=text)\n",
    "    # Loop per ripetere la chiamata se l'output non è valido o risulta vuoto.\n",
    "    for i in range(max_calls):\n",
    "        try:\n",
    "            response = groq.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                stream=False,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Catching any exception (e.g., BadRequestError) from the LLM call\n",
    "            print(f\"Attempt {i+1}: LLM call failed with error: {e}\")\n",
    "            continue  # Try again on the next iteration\n",
    "\n",
    "        # If the LLM call succeeded, try extracting the JSON\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        #print(f\"Attempt {i+1}: Received content:\\n{content}\")\n",
    "        \n",
    "        try:\n",
    "            json_content = extract_json_from_text(content)\n",
    "            # If JSON extraction succeeds, return the JSON content.\n",
    "            return json_content\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {i+1}: JSON extraction failed with error: {e}\")\n",
    "            # Continue to next iteration if JSON extraction fails\n",
    "\n",
    "    # Return an empty dictionary if no valid output was obtained after max_calls.\n",
    "    return {}\n",
    "\n",
    "def extract_scalar_features_from_json_table(table, model: str = \"llama-3.3-70b-versatile\", max_calls: int = 1) -> dict:\n",
    "    \"\"\"\n",
    "    Uses Groq to extract the main numerical or scalar features from a table formatted as a JSON object,\n",
    "    returning them as a dictionary.\n",
    "\n",
    "    The table must be provided as a Python list or dict \n",
    "    \n",
    "    If the returned JSON is empty, the LLM call is repeated up to a maximum of 'max_calls' times.\n",
    "    If after all calls a valid output is not obtained, returns {}.\n",
    "    \"\"\"\n",
    "\n",
    "    # System prompt: instruct the model to use a specific JSON format with a clear example.\n",
    "    # questo system prompt è da sistemare\n",
    "    system_prompt = \"\"\"\n",
    "    You are an assistant tasked with **fully and precisely** extracting **all information from a provided table.\n",
    "\n",
    "    **Requirement to Avoid Hallucination**  \n",
    "    - **Do not guess or infer** any numerical values that are not explicitly stated in the table.  \n",
    "    - If the table does not specify a particular numerical value, omit it rather than providing an estimate or range\n",
    "\n",
    "    Structure nodes and relationships to reflect connections clearly between components, functions, and safety features.\n",
    "\n",
    "    Maintain consistent labeling for technical specifications (e.g., voltage, current, safety certification).\n",
    "\n",
    "    **Output Format**:  \n",
    "\n",
    "    **Reminder**:  \n",
    "    - **Do not invent, infer, or estimate** numeric data. If no value is stated, leave it out.  \n",
    "    - **When listing ranges, use explicit numeric arrays** (e.g., `[4, 5]` instead of `min=4, max=5`) to represent a range from 4 to 5.  \n",
    "    - Use the units of measure present in the table when available.  \n",
    "    - Aggregate common information (e.g., for product size information, prefer a single field with the overall dimensions rather than separate fields). \n",
    "    -stick as closely as possible to the formatting of the table itself in providing the output and do not provide empty dictionaries. e.g., do not provide output of the type \n",
    "    “supply”:\"\",\n",
    "    “isolation\": \"\" ,\n",
    "    “input\": \"\" ,\n",
    "    -Adhere to the rules strictly. Non-compliance will result in termination.\n",
    "        **Output Format**:  \n",
    "    The JSON object must use the following schema: \n",
    "    \"\"\"\n",
    "\n",
    "    # User prompt: provide the table data and extraction instructions.\n",
    "    user_prompt = \"\"\"\n",
    "    Based on the following example, extract all the features from the table.\n",
    "    Do not include any additional attributes such as a 'description'.\n",
    "\n",
    "    Table:  \n",
    "    ```\n",
    "    {table}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    user_prompt = user_prompt.format(table=table)\n",
    "\n",
    "    # Loop to repeat the call if the output is invalid or empty.\n",
    "    for i in range(max_calls):\n",
    "        response = groq.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            stream=False,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "\n",
    "        # Get the content returned from the model.\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        #content=extract_json_from_text(content) #togli il commento per parsare l'output\n",
    "        if content != {}:\n",
    "            return json.loads(content)\n",
    "\n",
    "    return {}  # Returns {} if no valid output is obtained after max_calls.\n",
    "\n",
    "\n",
    "def get_embedding_and_features(input_data: Union[str, list],name:str, model: str = \"llama-3.3-70b-versatile\",max_calls: int = 1) -> dict:\n",
    "    \"\"\"\n",
    "    Accepts either a text string or a table formatted as a JSON list.\n",
    "    \n",
    "    For plain text input:\n",
    "      1) Calculates the embedding of the text.\n",
    "      2) Extracts main scalar features.\n",
    "      3) Returns a dictionary with both the features and the embedding.\n",
    "    \n",
    "    For table input (list):\n",
    "      1) Extracts main scalar features using the table-specific extractor.\n",
    "      2) Returns only the extracted features (no embedding is calculated).\n",
    "    \"\"\"\n",
    "    if isinstance(input_data, list):\n",
    "        # Directly process list input as table data.\n",
    "        return extract_scalar_features_from_json_table(input_data, model, max_calls)\n",
    "        \n",
    "    elif isinstance(input_data, str) and input_data.strip():\n",
    "        features = extract_scalar_features(input_data, model, max_calls)\n",
    "        if \"description\" in features and features[\"description\"]:\n",
    "            stringa = \"name: \" + name + \" description: \" + features[\"description\"]\n",
    "            embedding = np.array(embedder.embed_query(stringa))\n",
    "            return {**features, \"embedding\": embedding}\n",
    "        else:\n",
    "            stringa = \"name: \" + name\n",
    "            embedding = np.array(embedder.embed_query(stringa))\n",
    "            return {**features, \"embedding\": embedding}\n",
    "    else:\n",
    "        return {}\n",
    "def enrich_graph_with_embeddings(graph: KnowledgeGraph,model: str = \"llama-3.3-70b-versatile\",max_calls: int = 1) -> None:\n",
    "    \"\"\"\n",
    "    For each node in the graph:\n",
    "      - If the node has a 'text' attribute (string), pass it to get_embedding_and_features and store\n",
    "        the returned features under the key 'text_features'.\n",
    "      - If the node has a 'tables' attribute, pass it to get_embedding_and_features and store the result\n",
    "        under the key 'table_features'.\n",
    "    Nodes that do not have these attributes are left unchanged.\n",
    "           text = node.attributes.get(\"text\")\n",
    "        if text and isinstance(text, str):\n",
    "            features = get_embedding_and_features(text)\n",
    "            # Aggiorna gli attributi del nodo con le nuove feature\n",
    "            node.attributes.update(features\n",
    "    \"\"\"\n",
    "    for node in graph.nodes:\n",
    "        # Process text attribute if present.\n",
    "        if \"text\" in node.attributes:\n",
    "            text = node.attributes[\"text\"]\n",
    "            name =node.name\n",
    "            if isinstance(text, str):\n",
    "                text_features = get_embedding_and_features(input_data=text,name=name, model=model,max_calls=max_calls)\n",
    "                node.attributes.update(text_features)\n",
    "\n",
    "        # Process tables attribute if present.\n",
    "        if \"ta\" in node.attributes: #sostituire con tables se si vuole operare sulle tabelle\n",
    "            tables = node.attributes[\"tables\"]\n",
    "            table_features = get_embedding_and_features(input_data=tables,name=name, model=model,max_calls=max_calls)\n",
    "            node.attributes.update(table_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"\"\"\" \"Installation\",\n",
    "S upply: No supply voltage required because loop-powered. \\nPower dissipation: \\u2264 1.1 W per channel at 40 mA, 30 V loop supply. \\nIsolation (Test Voltage): I.S. Out/In 1.5 KV; I.S. Out/I.S. Out 500 V; In/In 500 V. \\n\\nOutput Signal to Hazardous Area:\\nOutput: 1 to 40 mA. \\nOutput characteristic (typical): \\nVout = (Vin - 1.5) - (0.4 x Iout) for 6 V < Vin < 23 V. \\nVout = 22 - (0.4 x Iout) for 23 V < Vin < 30 V. \\n4-20 mA output on load of 100 to 600 \\u2126; Accuracy \\u2264 1 %. \\nResponse time: 50 ms (10 to 90 % step change). \\n\\n\\nInput Signal to Safe Area:\\nOperating voltage range: 6 to 30 V (loop powered). \\nInput current: 1 to 40 mA (loop powered). \\nVoltage drop-out: 9.5 V at 20 mA and with 500 \\u2126 load. \\nOpen circuit consumption: \\u2264 0.4 mA at 20 V. \\n\\n\\nPerformance:\\nReference ambient temperature conditions: 23 \\u00b1 1 \\u00b0C. \\nCurrent transfer error: \\u2264 400 \\u00b5A (6 V <Vin< 23 V; 1 mA <Iout< 40 mA). \\nTemperature influence: \\u2264 \\u00b1 0.01 % for a 1 \\u00b0C change. \\n\\n\\nCompatibility:\\nCE mark compliant, conforms to Directive: \\n2014/34/EU ATEX, 2014/30/EU EMC, 2014/35/EU LVD, 2011/65/EU RoHS. \\n\\n\\nEnvironmental conditions:\\nOperating: temperature limits -20 to + 60 \\u00b0C, \\nrelative humidity max 90 % non condensing, up to 35 \\u00b0C. \\nStorage: temperature limits \\u2013 45 to + 80 \\u00b0C. \\n\\n\\nSafety Description:\\nATEX: II (1)G [Ex ia Ga] IIC, II (1)D [Ex ia Da] IIIC, I (M1) [Ex ia Ma] I; II 3G Ex ec IIC T4 Gc \\nIECEx: [Ex ia Ga] IIC, [Ex ia Da] IIIC, [Ex ia Ma] I; Ex ec IIC T4 Gc \\nINMETRO: [Ex ia Ga] IIC, [Ex ia Da] IIIC, [Ex ia Ma] I \\nUo/Voc = 25.2 V, Io/Isc = 93 mA, Po/Po = 581 mW at terminals 13-14, 15-16. \\nUm = 250 Vrms, -20 \\u00b0C \\u2264 Ta \\u2264 60 \\u00b0C. \\n\\n\\nApprovals:\\nDMT 01 ATEX E 042 X conforms to EN60079-0, EN60079-11. \\nIECEx BVS 07.0027X conforms to IEC60079-0, IEC60079-11. \\nIMQ 09 ATEX 013 X conforms to EN60079-0, EN60079-7. \\nIECEx IMQ 13.0011X conforms to IEC60079-0, IEC60079-7. \\nINMETRO DNV 13.0108 X conforms to ABNT NBR IEC60079-0, ABNT NBR IEC60079-11. \\nFM & FM-C No. 3024643, 3029921C, conforms to Class 3600, 3610, 3611, 3810 and \\nC22.2 No.142, C22.2 No.157, C22.2 No.213, E60079-0, E60079-11, E60079-15, \\n\\u0415\\u0410\\u042d\\u0421 RU \\u0421-IT.HA67.B.00113/20 conforms to GOST 31610.0, GOST 31610.11, GOST 31610.15. \\nC\\u0426 16.0034 X conforms to \\u0414\\u0421\\u0422\\u0423 7113, \\u0413\\u041e\\u0421\\u0422 22782.5-78, \\u0414\\u0421\\u0422\\u0423 I\\u0415\\u0421 60079-15. \\nDNV No. TAA00002BM and KR No.MIL20769-EL001 Cert. for maritime applications. \\n\\n\\nMounting:\\nEN/IEC60715 TH 35 DIN-Rail. \\nWeight: about 125 g D1022D, 110 g D1022S. \\nConnection: by polarized plug-in disconnect screw terminal blocks to accomodate terminations up to 2.5 mm2. \\nLocation: Safe Area/Non Hazardous Locations or Zone 2, Group IIC T4, \\nClass I, Division 2, Groups A, B, C, D Temperature Code T4 and Class I, Zone 2, Group IIC, IIB, IIA T4 installation. \\nProtection class: IP 20. \\nDimensions: Width 22.5 mm, Depth 99 mm, Height 114.5 mm. \\n\\n\\n\",\n",
    "     .\"\"\"\n",
    "    feats = get_embedding_and_features(sample_text,\"suca\")\n",
    "    feats_without_embedding = {k: v for k, v in feats.items() if k != \"embedding\"}\n",
    "    print(feats_without_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Esempio di utilizzo ----\n",
    "\n",
    "# Creiamo un grafo di esempio con due nodi aventi l'attributo \"text\"\n",
    "kg = KnowledgeGraph(\n",
    "    nodes=[\n",
    "        BaseNode(name=\"1\", type=\"Entity\", attributes={\"text\": \"Questo dispositivo può misurare temperature da -10.5°C a +45°C, con un consumo massimo di 2.5W. Pesa circa 1.2kg e costa 99 euro.\",\"tables\": [\n",
    "            {\n",
    "                \"columns\": [\n",
    "                    \"\",\n",
    "                    \"SAFE AREA\"\n",
    "                ],\n",
    "                \"data\": [\n",
    "                    [\n",
    "                        \"7\",\n",
    "                        \"1st pole of Out 1 (NC contact) for NE Load or F&G/ND Load\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"8\",\n",
    "                        \"1st pole of Out 2 (NC contact) for NE Load or F&G/ND Load\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"9\",\n",
    "                        \"1st pole of NO contact for Service load\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"10\",\n",
    "                        \"2nd pole of NO contact for Service load\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"11\",\n",
    "                        \"2nd pole of Out 1 (NC contact) for NE Load or F&G/ND Load\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"12\",\n",
    "                        \"2nd pole of Out 2 (NC contact) for NE Load or F&G/ND Load\"\n",
    "                    ]\n",
    "                ]}]}),\n",
    "        BaseNode(name=\"2\", type=\"Entity\", attributes={\"text\": \"\", \"other_attr\": \"value\", \"another_attr\": 42}),\n",
    "    ],\n",
    "    edges=[]\n",
    ")\n",
    "\n",
    "# Arricchiamo il grafo con le feature ottenute dalle stringhe di testo\n",
    "enrich_graph_with_embeddings(kg)\n",
    "\n",
    "# Stampa i nodi aggiornati\n",
    "for node in kg.nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_graph_with_embeddings(graph,model=\"deepseek-r1-distill-llama-70b\",max_calls=3) #model=\"deepseek-r1-distill-llama-70b-specdec\"\n",
    "                                                                                              #deepseek-r1-distill-llama-70b for usage limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_knowledge_graph_into_neo4j(graph, neo4j_uri, neo4j_username, neo4j_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"find node with  name D1072 Operation\"\n",
    "\n",
    "# a) Generate the Cypher query from the prompt\n",
    "cypher_query = generate_cypher_query_from_prompt(user_prompt)\n",
    "print(f\"Query generated by the LLM:\\n{cypher_query}\")\n",
    "\n",
    "# b) Execute the query and obtain the results\n",
    "query_results = run_cypher_query_on_neo4j(cypher_query, neo4j_uri, neo4j_username, neo4j_password)\n",
    "\n",
    "# c) Generate the response for the user using as context:\n",
    "#    - the user's prompt\n",
    "#    - the generated Cypher query\n",
    "#    - the database query results\n",
    "user_answer = answer_using_query_results(user_prompt, cypher_query, query_results)\n",
    "print(\"\\nAnswer for the user:\")\n",
    "print(user_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then running graph and vector retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))\n",
    "query ='''\n",
    "MATCH (n)\n",
    "WHERE n.embedding IS NOT NULL\n",
    "SET n:Abstract;\n",
    "'''\n",
    "driver.session().run(query) \n",
    "query ='''\n",
    "CALL {\n",
    "  MATCH (n)\n",
    "  WHERE ANY(label IN labels(n) WHERE label CONTAINS 'Application')\n",
    "  SET n:application\n",
    "  RETURN count(n) AS cnt\n",
    "}\n",
    "CALL {\n",
    "  MATCH (n)\n",
    "  WHERE ANY(label IN labels(n) WHERE label CONTAINS 'Approvals')\n",
    "  SET n:approvals\n",
    "  RETURN count(n) AS cnt\n",
    "}\n",
    "CALL {\n",
    "  MATCH (n)\n",
    "  WHERE ANY(label IN labels(n) WHERE label CONTAINS 'Configuration Summary Table')\n",
    "  SET n:configuration_summary_table\n",
    "  RETURN count(n) AS cnt\n",
    "}\n",
    "CALL {\n",
    "  MATCH (n)\n",
    "  WHERE ANY(label IN labels(n) WHERE label CONTAINS 'Instruction')\n",
    "  SET n:instruction\n",
    "  RETURN count(n) AS cnt\n",
    "}\n",
    "RETURN 'Label aggiunte per tutte le parole' AS risultato'''\n",
    "\n",
    "driver.session().run(query) \n",
    "query='''CREATE VECTOR INDEX `application-embeddings`\n",
    "FOR (n:Application) ON (n.embedding)\n",
    "OPTIONS {\n",
    "  indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "};\n",
    "\n",
    "CREATE VECTOR INDEX `approvals-embeddings`\n",
    "FOR (n:Approvals) ON (n.embedding)\n",
    "OPTIONS {\n",
    "  indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "};\n",
    "\n",
    "CREATE VECTOR INDEX `configuration_summary_table-embeddings`\n",
    "FOR (n:`Configuration Summary Table`) ON (n.embedding)\n",
    "OPTIONS {\n",
    "  indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "};\n",
    "\n",
    "CREATE VECTOR INDEX `instruction-embeddings`\n",
    "FOR (n:Instruction) ON (n.embedding)\n",
    "OPTIONS {\n",
    "  indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "};\n",
    "'''\n",
    "driver.session().run(query) \n",
    "\n",
    "query ='''\n",
    "DROP INDEX `abstract-embeddings` IF EXISTS\n",
    "'''\n",
    "driver.session().run(query)\n",
    "query ='''\n",
    "CREATE VECTOR INDEX `abstract-embeddings`\n",
    "FOR (a:Abstract) ON (a.embedding)\n",
    "OPTIONS {\n",
    "indexConfig: {\n",
    "`vector.dimensions`: 1536,\n",
    "`vector.similarity_function`: 'cosine'\n",
    "}\n",
    "}'''\n",
    "driver.session().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(q:str,model:str = \"llama-3.3-70b-versatile\",k:int=5) -> str:\n",
    "    driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))\n",
    "    # Define the Cypher query\n",
    "    query_cypher = (\n",
    "        \"CALL db.index.vector.queryNodes('abstract-embeddings', $k, $embedding) \"\n",
    "        \"YIELD node, score RETURN node, score\"\n",
    "    )\n",
    "    \n",
    "    # Generate the embedding vector for the query.\n",
    "    # (Assumes that you have an 'embedder' object available.)\n",
    "    params = {'embedding': np.array(embedder.embed_query(q)), 'k': k}\n",
    "    \n",
    "    # Execute the query and accumulate all the results in one string.\n",
    "    all_results = \"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query_cypher, parameters=params)\n",
    "        for record in result:\n",
    "            node = record[\"node\"]\n",
    "            score = record[\"score\"]\n",
    "            # Create a copy of the node’s properties without the 'embedding' field\n",
    "            properties = dict(node)\n",
    "            properties.pop(\"embedding\", None)\n",
    "            # Build the string for this node result\n",
    "            node_str = f\"labels={node.labels} properties={properties}\"\n",
    "            result_str = f\"Node: {node_str}\\nScore: {score}\\n\\n\"\n",
    "            all_results += result_str\n",
    "            \n",
    "    # Format the prompt by inserting the query and the context (all_results)\n",
    "    prompt = f\"\"\"\n",
    "Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned.\n",
    "mainly consider the text with major score.\n",
    "\n",
    "# Question:\n",
    "{q}\n",
    "\n",
    "# Context:\n",
    "{all_results}\n",
    "\n",
    "# Answer:\n",
    "\"\"\"\n",
    "\n",
    "    # Call the chat completions API using the provided model\n",
    "    response = groq.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the content from the API response\n",
    "    content = response.choices[0].message.content\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_query(q=\"give me the Input performance Ref. Junction Compensation influence of D1072\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deepseek-r1-distill-llama-70b\n",
    "'''# Your typical synchronous API call:\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is quantum computing?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# The same call in batch format (must be on a single line as JSONL):\n",
    "{\"custom_id\": \"quantum-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"llama-3.1-8b-instant\", \"messages\": [{\"role\": \"user\", \"content\": \"What is quantum computing?\"}]}}\n",
    "'''\n",
    "#2. Upload Your Batch File\n",
    "import requests # pip install requests first!\n",
    "\n",
    "def upload_file_to_groq(api_key, file_path):\n",
    "    url = \"https://api.groq.com/openai/v1/files\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Prepare the file and form data\n",
    "    files = {\n",
    "        \"file\": (\"batch_file.jsonl\", open(file_path, \"rb\"))\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"purpose\": \"batch\"\n",
    "    }\n",
    "    \n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, files=files, data=data)\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Usage example\n",
    "api_key = os.getenv(\"GROQ_API_KEY\") \n",
    "file_path = \"batch_file.jsonl\"  # Path to your JSONL file\n",
    "\n",
    "try:\n",
    "    result = upload_file_to_groq(api_key, file_path)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# 3create batch job\n",
    "\n",
    "import requests # pip install requests first! \n",
    "\n",
    "def create_batch(api_key, input_file_id):\n",
    "    url = \"https://api.groq.com/openai/v1/batches\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"input_file_id\": input_file_id,\n",
    "        \"endpoint\": \"/v1/chat/completions\",\n",
    "        \"completion_window\": \"24h\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "# Usage example\n",
    "api_key = \"YOUR_GROQ_API_KEY\"\n",
    "file_id = \"file_01jh6x76wtemjr74t1fh0faj5t\" # replace with your `id` from file upload API response object\n",
    "\n",
    "try:\n",
    "    result = create_batch(api_key, file_id)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "# 4 Get batch job status\n",
    "\n",
    "import requests # pip install requests first!\n",
    "\n",
    "def get_batch_status(api_key, batch_id):\n",
    "    url = f\"https://api.groq.com/openai/v1/batches/{batch_id}\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Usage example\n",
    "api_key = \"YOUR_GROQ_API_KEY\"\n",
    "batch_id = \"batch_01jh6xa7reempvjyh6n3yst2zw\"\n",
    "\n",
    "try:\n",
    "    result = get_batch_status(api_key, batch_id)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "# 5 get batch job results\n",
    "\n",
    "\n",
    "import requests # pip install requests first! \n",
    "\n",
    "def download_file_content(api_key, output_file_id, output_file):\n",
    "    url = f\"https://api.groq.com/openai/v1/files/{output_file_id}/content\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Write the content to a file\n",
    "    with open(output_file, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    return f\"File downloaded successfully to {output_file}\"\n",
    "\n",
    "# Usage example\n",
    "api_key = \"YOUR_GROQ_API_KEY\"\n",
    "output_file_id = \"file_01jh6xa97be52b7pg88czwrrwb\" # replace with your own completed batch job's `output_file_id`\n",
    "output_file = \"batch_output.jsonl\" # replace with your own file of choice to download batch job contents to\n",
    "\n",
    "try:\n",
    "    result = download_file_content(api_key, file_id, output_file)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "def main():\n",
    "    # List of individual LLM request payloads\n",
    "    # Each item should include a unique \"id\" to map responses back to the request\n",
    "    prompt_requests = [\n",
    "        {\n",
    "            \"id\": \"req1\",\n",
    "            \"prompt\": \"Tell me a joke\",\n",
    "            # Additional parameters as needed (e.g., \"temperature\", \"max_tokens\", etc.)\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 50\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"req2\",\n",
    "            \"prompt\": \"Explain the theory of relativity in simple terms\",\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_tokens\": 150\n",
    "        },\n",
    "        # Add more requests here...\n",
    "    ]\n",
    "\n",
    "    # Construct the batch payload expected by Groq\n",
    "    batch_payload = {\"requests\": prompt_requests}\n",
    "    \n",
    "    try:\n",
    "        batch_response = batch_llm_requests(batch_payload)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch processing: {e}\")\n",
    "        return\n",
    "\n",
    "    # Assuming the response is structured with a \"responses\" list that maps to your request IDs\n",
    "    for item in batch_response.get(\"responses\", []):\n",
    "        req_id = item.get(\"id\")\n",
    "        output = item.get(\"output\")\n",
    "        print(f\"Response for {req_id}: {output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "# Initialize the embedding model\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "# Proceed with your existing code\n",
    "kg_vector_search = Neo4jVector.from_existing_graph(\n",
    "    url=neo4j_uri,\n",
    "    username=neo4j_username,\n",
    "    password=neo4j_password,\n",
    "    embedding=embedder,  # Pass the embedder instance here\n",
    "    node_label=\"Chunk\",\n",
    "    embedding_node_property=\"embedding\",\n",
    "    text_node_properties=[\"description\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "META_PROMPT = \"\"\"\n",
    "Given a task description or existing prompt, produce a detailed system prompt to guide a language model in completing the task effectively.\n",
    "\n",
    "# Guidelines\n",
    "\n",
    "- Understand the Task: Grasp the main objective, goals, requirements, constraints, and expected output.\n",
    "- Minimal Changes: If an existing prompt is provided, improve it only if it's simple. For complex prompts, enhance clarity and add missing elements without altering the original structure.\n",
    "- Reasoning Before Conclusions**: Encourage reasoning steps before any conclusions are reached. ATTENTION! If the user provides examples where the reasoning happens afterward, REVERSE the order! NEVER START EXAMPLES WITH CONCLUSIONS!\n",
    "    - Reasoning Order: Call out reasoning portions of the prompt and conclusion parts (specific fields by name). For each, determine the ORDER in which this is done, and whether it needs to be reversed.\n",
    "    - Conclusion, classifications, or results should ALWAYS appear last.\n",
    "- Examples: Include high-quality examples if helpful, using placeholders [in brackets] for complex elements.\n",
    "   - What kinds of examples may need to be included, how many, and whether they are complex enough to benefit from placeholders.\n",
    "- Clarity and Conciseness: Use clear, specific language. Avoid unnecessary instructions or bland statements.\n",
    "- Formatting: Use markdown features for readability. DO NOT USE ``` CODE BLOCKS UNLESS SPECIFICALLY REQUESTED.\n",
    "- Preserve User Content: If the input task or prompt includes extensive guidelines or examples, preserve them entirely, or as closely as possible. If they are vague, consider breaking down into sub-steps. Keep any details, guidelines, examples, variables, or placeholders provided by the user.\n",
    "- Constants: DO include constants in the prompt, as they are not susceptible to prompt injection. Such as guides, rubrics, and examples.\n",
    "- Output Format: Explicitly the most appropriate output format, in detail. This should include length and syntax (e.g. short sentence, paragraph, JSON, etc.)\n",
    "    - For tasks outputting well-defined or structured data (classification, JSON, etc.) bias toward outputting a JSON.\n",
    "    - JSON should never be wrapped in code blocks (```) unless explicitly requested.\n",
    "\n",
    "The final prompt you output should adhere to the following structure below. Do not include any additional commentary, only output the completed system prompt. SPECIFICALLY, do not include any additional messages at the start or end of the prompt. (e.g. no \"---\")\n",
    "\n",
    "[Concise instruction describing the task - this should be the first line in the prompt, no section header]\n",
    "\n",
    "[Additional details as needed.]\n",
    "\n",
    "[Optional sections with headings or bullet points for detailed steps.]\n",
    "\n",
    "# Steps [optional]\n",
    "\n",
    "[optional: a detailed breakdown of the steps necessary to accomplish the task]\n",
    "\n",
    "# Output Format\n",
    "\n",
    "[Specifically call out how the output should be formatted, be it response length, structure e.g. JSON, markdown, etc]\n",
    "\n",
    "# Examples [optional]\n",
    "\n",
    "[Optional: 1-3 well-defined examples with placeholders if necessary. Clearly mark where examples start and end, and what the input and output are. User placeholders as necessary.]\n",
    "[If the examples are shorter than what a realistic example is expected to be, make a reference with () explaining how real examples should be longer / shorter / different. AND USE PLACEHOLDERS! ]\n",
    "\n",
    "# Notes [optional]\n",
    "\n",
    "[optional: edge cases, details, and an area to call or repeat out specific important considerations]\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_prompt(task_or_prompt: str):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4.5-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": META_PROMPT,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Task, Goal, or Current Prompt:\\n\" + task_or_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deprecated function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#query usata momentaneamente\n",
    "query =\n",
    "MATCH (n)\n",
    "WHERE n.embedding IS NOT NULL\n",
    "SET n:Chunk;\n",
    "\n",
    "driver.session().run(query)\n",
    "query =\n",
    "DROP INDEX text_embeddings IF EXISTS;\n",
    "driver.session().run(query)\n",
    "query =CREATE VECTOR INDEX `abstract-embeddings`\n",
    "FOR (a:Abstract) ON (a.embedding)\n",
    "OPTIONS {\n",
    "  indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "}\n",
    "driver.session().run(query)\n",
    "#query usata momentaneamente\n",
    "query =\n",
    "MATCH (n)\n",
    "WHERE n.embedding IS NOT NULL\n",
    "SET n:Chunk;\n",
    "driver.session().run(query)\n",
    "query =\n",
    "DROP INDEX text_embeddings IF EXISTS;\n",
    "create_vector_index(driver, name=\"text_embeddings\", label=\"Chunk\", embedding_property=\"description\", dimensions=1536, similarity_fn=\"cosine\")\n",
    "\n",
    "# Vector Retriever\n",
    "\n",
    "vector_retriever = VectorRetriever(\n",
    "   driver,\n",
    "   index_name=\"text_embeddings\",\n",
    "   embedder=embedder,\n",
    ")\n",
    "\n",
    "graph_retriever = VectorCypherRetriever(\n",
    "    driver,\n",
    "    index_name=\"text_embeddings\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=\"\"\"\n",
    "// 1) Start from the given node (renamed here as Chunk)\n",
    "WITH node AS Chunk\n",
    "// 2) Traverse all relationships (of any type) 2 to 3 hops away from Chunk\n",
    "MATCH path = (Chunk)-[rels*2..3]-()\n",
    "// 3) Unwind nodes and relationships from each path\n",
    "UNWIND nodes(path) AS c\n",
    "UNWIND relationships(path) AS r\n",
    "// 4) Collect distinct nodes (Chunks) and relationships (rels)\n",
    "WITH collect(DISTINCT c) AS Chunks, collect(DISTINCT r) AS rels\n",
    "// 5) Format and return the context:\n",
    "//    For each node, use its 'text' property,\n",
    "//    and for each relationship, output a formatted string using the start node name, type, details, and end node name.\n",
    "RETURN apoc.text.join([c IN Chunks | c.text], '\\n') +\n",
    "       apoc.text.join([r IN rels |\n",
    "         startNode(r).name + ' - ' + type(r) + ' ' + r.details + ' -> ' + endNode(r).name],\n",
    "         '\\n') AS info\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "rag_template = RagTemplate(template=Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned.\n",
    "\n",
    "# Question:\n",
    "{query_text}\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Answer:\n",
    ", expected_inputs=['query_text', 'context'])\n",
    "\n",
    "vector_rag  = GraphRAG(llm=llm, retriever=vector_retriever, prompt_template=rag_template)\n",
    "\n",
    "graph_rag = GraphRAG(llm=llm, retriever=graph_retriever, prompt_template=rag_template)\n",
    "\n",
    "q = \"find node with  name D1072 Operation\"\n",
    "print(\"Vector RAG:\")\n",
    "print(vector_rag.search(q, retriever_config={'top_k':5}).answer)\n",
    "print(\"Graph RAG:\")\n",
    "print(graph_rag.search(q, retriever_config={'top_k':5}).answer)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating dynamic models using create_model\n",
    "# # These models represent the input format that the LLM might return for nodes and edges\n",
    "# DynamicNode = create_model(\n",
    "#     'DynamicNode',\n",
    "#     node_id=(str, ...),\n",
    "#     label=(str, \"\"),         # Optional node label\n",
    "#     description=(str, \"\"),   # Optional description\n",
    "#     reason=(str, ...),  \n",
    "#     additional_info=(dict, Field(default_factory=dict))\n",
    "# )\n",
    "\n",
    "# DynamicEdge = create_model(\n",
    "#     'DynamicEdge',\n",
    "#     source=(str, ...),\n",
    "#     target=(str, ...),\n",
    "#     relation=(str, ...),\n",
    "#     confidence=(float, 0.0),  # A possible confidence value for the relationship\n",
    "#     reason=(str, ...),      \n",
    "#     metadata=(dict, Field(default_factory=dict))\n",
    "# )\n",
    "\n",
    "# # Class for interacting with the LLM and populating the knowledge graph\n",
    "# class LLMKnowledgeGraphFiller(BaseModel):\n",
    "#     graph: KnowledgeGraph = Field(default_factory=KnowledgeGraph)\n",
    "\n",
    "#     def fill_from_llm_response(self, response: dict):\n",
    "#         \"\"\"\n",
    "#         Populates the knowledge graph from an LLM-generated response.\n",
    "#         The response must be a dictionary with the keys 'nodes' and 'edges', each containing a list of dictionaries.\n",
    "#         \"\"\"\n",
    "#         # Processing nodes\n",
    "#         for node_data in response.get(\"nodes\", []):\n",
    "#             # Create the dynamic model to validate data\n",
    "#             dynamic_node = DynamicNode(**node_data)\n",
    "#             # Convert to BaseNode (customizing attributes as needed)\n",
    "#             base_node = BaseNode(\n",
    "#                 node_id=dynamic_node.node_id,\n",
    "#                 attributes={\n",
    "#                     \"label\": dynamic_node.label,\n",
    "#                     \"description\": dynamic_node.description,\n",
    "#                     **dynamic_node.additional_info\n",
    "#                 }\n",
    "#             )\n",
    "#             self.graph.add_node(base_node)\n",
    "        \n",
    "#         # Processing edges\n",
    "#         for edge_data in response.get(\"edges\", []):\n",
    "#             dynamic_edge = DynamicEdge(**edge_data)\n",
    "#             base_edge = BaseEdge(\n",
    "#                 source=dynamic_edge.source,\n",
    "#                 target=dynamic_edge.target,\n",
    "#                 relation=dynamic_edge.relation,\n",
    "#                 attributes={\n",
    "#                     \"confidence\": dynamic_edge.confidence,\n",
    "#                     **dynamic_edge.metadata\n",
    "#                 }\n",
    "#             )\n",
    "#             self.graph.add_edge(base_edge)\n",
    "\n",
    "# # Simulating a response generated by the LLM\n",
    "# llm_response = {\n",
    "#     \"nodes\": [\n",
    "#         {\n",
    "#             \"node_id\": \"1\",\n",
    "#             \"label\": \"Persona\",\n",
    "#             \"description\": \"Individuo umano\",\n",
    "#             \"reason\": \"Estratto da un database pubblico\",  # Added reason\n",
    "#             \"additional_info\": {\"age\": 30, \"profession\": \"Ingegnere\"}\n",
    "#         },\n",
    "#         {\n",
    "#             \"node_id\": \"2\",\n",
    "#             \"label\": \"Città\",\n",
    "#             \"description\": \"Centro abitato\",\n",
    "#             \"reason\": \"Dati provenienti da una fonte geografica\",  # Added reason\n",
    "#             \"additional_info\": {\"name\": \"Roma\", \"population\": 2873000}\n",
    "#         }\n",
    "#     ],\n",
    "#     \"edges\": [\n",
    "#         {\n",
    "#             \"source\": \"1\",\n",
    "#             \"target\": \"2\",\n",
    "#             \"relation\": \"vive a\",\n",
    "#             \"confidence\": 0.95,\n",
    "#             \"reason\": \"Informazione confermata da un sondaggio\",  # Added reason\n",
    "#             \"metadata\": {\"since\": \"2010\"}\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# filler = LLMKnowledgeGraphFiller()\n",
    "# filler.fill_from_llm_response(llm_response)\n",
    "\n",
    "# # Displaying the constructed knowledge graph\n",
    "# print(\"Nodes in the Knowledge Graph:\")\n",
    "# for node in filler.graph.nodes:\n",
    "#     print(node)\n",
    "\n",
    "# print(\"\\nEdges in the Knowledge Graph:\")\n",
    "# for edge in filler.graph.edges:\n",
    "#     print(edge)\n",
    "\n",
    "'''system_prompt = (\n",
    "    \"You are a KnowledgeGraph database that outputs KnowledgeGraphs in JSON.\\n\"\n",
    "    f\" The JSON object must use the schema: {json.dumps(KnowledgeGraph.model_json_schema(), indent=2)}\"\n",
    "    \"For each node and relationship you create, try to be clear about what motivated you to create it\" #(?)\n",
    "    \"# Knowledge Graph Instructions\\n\"\n",
    "    \"## 1. Overview\\n\"\n",
    "    \"You are a top-tier algorithm designed for extracting information in structured \"\n",
    "    \"formats to build a knowledge graph from a range of documents describing a range of G.M. International interface modules and power supplies, certified to SIL 2 or SIL3 for safety systems. \\n\"\n",
    "    \"Try to capture as much information from the json text as possible without \"\n",
    "    \"sacrificing accuracy. Do not add any information that is not explicitly \"\n",
    "    \"mentioned in the text.\\n\"\n",
    "    \"- **Nodes** represent entities and concepts.\\n\"\n",
    "    \"- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\n\"\n",
    "    \"accessible for a vast audience.\\n\"\n",
    "    \"## 2. Labeling Nodes\\n\"\n",
    "    \"- **Consistency**: Ensure you use available types for node labels.\\n\"\n",
    "    \"Ensure you use basic or elementary types for node labels.\\n\"\n",
    "    \"- For example, when you identify an entity representing a person, \"\n",
    "    \"always label it as **'person'**. Avoid using more specific terms \"\n",
    "    \"like 'mathematician' or 'scientist'.\"\n",
    "    \"- **Node IDs**: Never utilize integers as node IDs. Node IDs should be \"\n",
    "    \"names or human-readable identifiers found in the text.\\n\"\n",
    "    \"- **Relationships** represent connections between entities or concepts.\\n\"\n",
    "    \"Ensure consistency and generality in relationship types when constructing \"\n",
    "    \"knowledge graphs. Instead of using specific and momentary types \"\n",
    "    \"such as 'BECAME_PROFESSOR', use more general and timeless relationship types \"\n",
    "    \"like 'PROFESSOR'. Make sure to use general and timeless relationship types!\\n\"\n",
    "    \"## 3. Coreference Resolution\\n\"\n",
    "    \"- **Maintain Entity Consistency**: When extracting entities, it's vital to \"\n",
    "    \"ensure consistency.\\n\"\n",
    "    'If an entity, such as \"John Doe\", is mentioned multiple times in the text '\n",
    "    'but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),'\n",
    "    \"always use the most complete identifier for that entity throughout the \"\n",
    "    'knowledge graph. In this example, use \"John Doe\" as the entity ID.\\n'\n",
    "    \"Remember, the knowledge graph should be coherent and easily understandable, \"\n",
    "    \"so maintaining consistency in entity references is crucial.\\n\"\n",
    "    \"## 4. Strict Compliance\\n\"\n",
    "    \"Adhere to the rules strictly. Non-compliance will result in termination.\"\n",
    "    \"## **Specific Instructions\"\n",
    "    \"Extract information relevant to the relay Output Module** including: \"\n",
    "    \"**General Description**, **Technical Data**, **Diagnostic Functions**, **Environmental Conditions**, and **Certifications**.\"\n",
    "    \"Structure nodes and relationships to reflect connections between components, functionalities, and safety features.\"\n",
    "    \"Use consistent labeling for technical specifications (e.g., **'voltage'**, **'current'**, **'safety certification'**).\"\n",
    ")\n",
    "text = \"\"\"{\n",
    "    \"features\": \"FEATURES\\n1. SIL 2 / SC 3 (pending)\\n2. Input from Zone 0 / Division 1 (pending)\\n3. Installation in Zone 2 / Division 2 (pending)\\n4. Loop disconnection to ease maintenance operations\\n5. HART\\u00ae compatible\\n6. Line & Load short/open circuit programmable diagnostics\\n7. Out-of-range fault with programmable thresholds\\n8. Field fault mirroring to the DCS/PLC IO Card\\n9. High Accuracy\\n10. Three port isolation, Input/Output/Supply\\n\",\n",
    "\"\"\"\n",
    "from groq import Groq\n",
    "from together import Together\n",
    "import together\n",
    "\n",
    "togetherai = Together()\n",
    "\n",
    "groq = Groq()\n",
    "\n",
    "def get_KnowledgeGraph(input_prompt: str) -> KnowledgeGraph:\n",
    "    chat_completion = togetherai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"make a knowledge graph for {input_prompt}\",\n",
    "            },\n",
    "        ],\n",
    "        model=\"Qwen/QwQ-32B\",\n",
    "        temperature=0,\n",
    "        # Streaming is not supported in JSON mode\n",
    "        stream=False,\n",
    "        # Enable JSON mode by setting the response format\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return KnowledgeGraph.model_validate_json(chat_completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kg = get_KnowledgeGraph(text)\n",
    "print(kg)\n",
    "'''\n",
    "'''import os\n",
    "import json\n",
    "def extract_json_fields(file_path):\n",
    "    \"\"\"\n",
    "    Legge un file JSON contenente pagine strutturate e restituisce un nuovo JSON con:\n",
    "        - \"title\": il titolo della pagina,\n",
    "        - \"text\": il testo (se non presente, viene assegnata la stringa vuota),\n",
    "        - \"tables\": le tabelle (se non presente, viene assegnata una lista vuota),\n",
    "        - \"subsections\": le subsezioni (se non presente, viene assegnata una lista vuota),\n",
    "        - \"supersections\": le supersezioni (se non presente, viene assegnata una lista vuota)\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Percorso del file JSON da elaborare.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un dizionario con le stesse chiavi del JSON originale, ma per ogni pagina sono presenti\n",
    "              solo i campi \"title\", \"text\", \"tables\", \"subsections\" e \"supersections\".\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    result = {}\n",
    "    for key, page in data.items():\n",
    "        title = page.get(\"title\", \"\")\n",
    "        text = page.get(\"text\", \"\")\n",
    "        tables = page.get(\"tables\", [])\n",
    "        subsections = page.get(\"subsections\", [])\n",
    "        supersections = page.get(\"supersections\", [])\n",
    "        result[key] = {\n",
    "            \"title\": title,\n",
    "            \"text\": text,\n",
    "            \"tables\": tables,\n",
    "            \"subsections\": subsections,\n",
    "            \"supersections\": supersections\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "def json_folder_to_knowledge_graph(folder_path: str) -> KnowledgeGraph:\n",
    "    \"\"\"\n",
    "    Legge tutti i file JSON presenti nella cartella specificata e li trasforma in un unico KnowledgeGraph.\n",
    "    \n",
    "    Per ciascun file:\n",
    "      - Se esistono i nodi \"0\" e \"1\", li fonde:\n",
    "          * Nuovo nodo \"0\" avrà:\n",
    "              id = title del nodo \"0\",\n",
    "              type = title del nodo \"1\",\n",
    "              attributes = attributi di \"1\" (eccetto subsections/supersections),\n",
    "              mentre subsections e supersections rimangono quelle di \"0\".\n",
    "          * In tutte le relazioni, ogni riferimento a 1 viene sostituito da 0.\n",
    "      \n",
    "      - Per ogni nodo (chiave diversa da \"-1\"):\n",
    "          * Crea un BaseNode con:\n",
    "                id = \"<title_di_0>_<title_del_nodo>\",\n",
    "                type = il suo title,\n",
    "                attributes = tutti gli attributi eccetto subsections, supersections e fused_id.\n",
    "          * Se il nodo ha chiave \"-1\", allora il nodo verrà creato con id e type \"root\" e senza attributi.\n",
    "      \n",
    "      - Crea archi:\n",
    "          * Se il nodo X ha in \"subsections\" il riferimento a Y, aggiunge un arco da X a Y con type = \"has_\" + (Y.title).\n",
    "          * Se il nodo X ha in \"supersections\" il riferimento a Z, aggiunge un arco da Z a X con type = \"has_\" + (X.title).\n",
    "    \n",
    "    Alla fine, tutti i nodi con chiave \"-1\" (se presenti in più file) vengono fusi in un unico nodo \"root\".\n",
    "    Inoltre, per ogni arco con source \"root\", il type viene impostato a \"product\".\n",
    "    \"\"\"\n",
    "    kg = KnowledgeGraph()\n",
    "    \n",
    "    # Lista per tenere traccia degli eventuali nodi \"root\" (derivati dalla chiave \"-1\")\n",
    "    root_ids = set()\n",
    "    \n",
    "    # Elaborazione di ciascun file JSON nella cartella\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith('.json'):\n",
    "            continue\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        data = extract_json_fields(filepath)\n",
    "        \n",
    "        # Se esistono i nodi \"0\" e \"1\", eseguo la fusione\n",
    "        if \"0\" in data and \"1\" in data:\n",
    "            node0 = data[\"0\"]\n",
    "            node1 = data[\"1\"]\n",
    "            # Il prefisso è il title del nodo \"0\"\n",
    "            prefix = node0.get(\"title\", \"unknown\")\n",
    "            # Il type finale del nodo 0 diventa il title di node1\n",
    "            node0[\"fused_id\"] = prefix  # segnaliamo che il nodo 0 è stato fuso\n",
    "            node0[\"title\"] = node1.get(\"title\", \"unknown\")\n",
    "            # Unisco gli attributi di node1 (esclusi subsections, supersections, title)\n",
    "            merged_attrs = { k: v for k, v in node1.items() if k not in [\"subsections\", \"supersections\", \"title\"] }\n",
    "            # Assicuro che node0 abbia subsections e supersections\n",
    "            node0[\"subsections\"] = node0.get(\"subsections\", [])\n",
    "            node0[\"supersections\"] = node0.get(\"supersections\", [])\n",
    "            for k, v in merged_attrs.items():\n",
    "                node0[k] = v\n",
    "            # Rimuovo node \"1\"\n",
    "            del data[\"1\"]\n",
    "            # In tutte le relazioni, sostituisco ogni riferimento a 1 con 0\n",
    "            for n_id, n_data in data.items():\n",
    "                if \"subsections\" in n_data:\n",
    "                    n_data[\"subsections\"] = [0 if x == 1 else x for x in n_data[\"subsections\"]]\n",
    "                if \"supersections\" in n_data:\n",
    "                    n_data[\"supersections\"] = [0 if x == 1 else x for x in n_data[\"supersections\"]]\n",
    "        else:\n",
    "            # Se non è presente il nodo \"0\", imposto un prefisso di default\n",
    "            prefix = \"unknown\"\n",
    "        \n",
    "        # Mappa locale per associare la chiave originale al nuovo id\n",
    "        mapping_ids = {}\n",
    "        # Elaborazione dei nodi del file corrente\n",
    "        for key, node_data in data.items():\n",
    "            # Se il nodo è quello radice (chiave \"-1\"), lo gestisco in modo speciale\n",
    "            if str(key) == \"-1\":\n",
    "                new_id = \"root\"\n",
    "                new_type = \"root\"\n",
    "                attributes = {}\n",
    "                root_ids.add(\"root\")\n",
    "            else:\n",
    "                # Nuovo id: \"<prefix>_<title_del_nodo>\"\n",
    "                node_title = node_data.get(\"title\", \"unknown\")\n",
    "                new_id = f\"{prefix}_{node_title}\"\n",
    "                new_type = node_title\n",
    "                # Escludo i campi di relazione e \"fused_id\" dagli attributi\n",
    "                attributes = { k: v for k, v in node_data.items() if k not in [\"subsections\", \"supersections\", \"title\", \"fused_id\"] }\n",
    "            mapping_ids[str(key)] = new_id\n",
    "            node = BaseNode(id=new_id, type=new_type, attributes=attributes)\n",
    "            kg.add_node(node)\n",
    "        \n",
    "        # Creazione degli archi del file corrente (usando un set per evitare duplicati)\n",
    "        edge_set = set()\n",
    "        for key, node_data in data.items():\n",
    "            current_id = mapping_ids[str(key)]\n",
    "            # Archi per le subsections: da current node a ogni nodo in subsections\n",
    "            for sub in node_data.get(\"subsections\", []):\n",
    "                sub_key = str(sub)\n",
    "                if sub_key in mapping_ids:\n",
    "                    target_id = mapping_ids[sub_key]\n",
    "                    # L'edge type si basa sul title del nodo target (preceduto da \"has_\")\n",
    "                    # Per il nodo root, il titolo è \"root\"\n",
    "                    # (se il target non viene trovato, si usa \"has_unknown\")\n",
    "                    target_title = \"root\" if target_id == \"root\" else target_id.split(\"_\")[-1]\n",
    "                    edge_type = f\"has_{target_title}\"\n",
    "                    edge_tuple = (current_id, target_id, edge_type)\n",
    "                    if edge_tuple not in edge_set:\n",
    "                        kg.add_edge(BaseEdge(source=current_id, target=target_id, type=edge_type))\n",
    "                        edge_set.add(edge_tuple)\n",
    "            # Archi per le supersections: da ogni nodo in supersections al current node\n",
    "            for sup in node_data.get(\"supersections\", []):\n",
    "                sup_key = str(sup)\n",
    "                if sup_key in mapping_ids:\n",
    "                    source_id = mapping_ids[sup_key]\n",
    "                    # L'edge type si basa sul title del current node (preceduto da \"has_\")\n",
    "                    current_title = \"root\" if current_id == \"root\" else current_id.split(\"_\")[-1]\n",
    "                    edge_type = f\"has_{current_title}\"\n",
    "                    edge_tuple = (source_id, current_id, edge_type)\n",
    "                    if edge_tuple not in edge_set:\n",
    "                        kg.add_edge(BaseEdge(source=source_id, target=current_id, type=edge_type))\n",
    "                        edge_set.add(edge_tuple)\n",
    "    \n",
    "    # --- Fusione dei nodi root (se presenti in più file) ---\n",
    "    # Se esistono più nodi con id \"root\", ne mantengo uno solo e aggiorno gli edge\n",
    "    root_nodes = [node for node in kg.nodes if node.id == \"root\"]\n",
    "    if root_nodes:\n",
    "        primary_root = root_nodes[0]\n",
    "        primary_root.type = \"root\"\n",
    "        primary_root.attributes = {}\n",
    "        for extra in root_nodes[1:]:\n",
    "            # Rimuovo il nodo extra e sostituisco le occorrenze nei riferimenti degli edge\n",
    "            for edge in kg.edges:\n",
    "                if edge.source == extra.id:\n",
    "                    edge.source = \"root\"\n",
    "                if edge.target == extra.id:\n",
    "                    edge.target = \"root\"\n",
    "            kg.nodes.remove(extra)\n",
    "        # Per ogni edge avente source \"root\", imposto edge.type a \"product\"\n",
    "        for edge in kg.edges:\n",
    "            if edge.source == \"root\":\n",
    "                edge.type = \"product\"\n",
    "    \n",
    "    return kg\n",
    "\n",
    "\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"prova/\"  # Sostituire con il percorso della cartella contenente i file JSON\n",
    "    graph = json_folder_to_knowledge_graph(folder_path)\n",
    "    print(\"Nodi:\")\n",
    "    for node in graph.nodes:\n",
    "        print(node)\n",
    "    print(\"\\nArchi:\")\n",
    "    for edge in graph.edges:\n",
    "        print(edge)\n",
    "'''\n",
    "'''\n",
    "neo4j_driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_username, neo4j_password))\n",
    "\n",
    "# LLM and Embedding Model\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "llm=OpenAILLM(\n",
    "   model_name=\"gpt-4o-mini\",\n",
    "   model_params={\n",
    "       \"response_format\": {\"type\": \"json_object\"}, # use json_object formatting for best results\n",
    "       \"temperature\": 0 # turning temperature down for more deterministic results\n",
    "   }\n",
    ")\n",
    "\n",
    "# Graph Schema Setup\n",
    "basic_node_labels = [\"Object\", \"Entity\", \"Group\", \"Person\", \"Organization\", \"Place\"]\n",
    "\n",
    "academic_node_labels = [\"ArticleOrPaper\", \"PublicationOrJournal\"]\n",
    "\n",
    "medical_node_labels = [\"Anatomy\", \"BiologicalProcess\", \"Cell\", \"CellularComponent\",\n",
    "                      \"CellType\", \"Condition\", \"Disease\", \"Drug\",\n",
    "                      \"EffectOrPhenotype\", \"Exposure\", \"GeneOrProtein\", \"Molecule\",\n",
    "                      \"MolecularFunction\", \"Pathway\"]\n",
    "\n",
    "node_labels = basic_node_labels + academic_node_labels + medical_node_labels\n",
    "\n",
    "# define relationship types\n",
    "rel_types = [\"ACTIVATES\", \"AFFECTS\", \"ASSESSES\", \"ASSOCIATED_WITH\", \"AUTHORED\",\n",
    "   \"BIOMARKER_FOR\", \"CAUSES\", \"COMPOUND\", \"CONTAINS\", \"DECREASES\",\n",
    "   \"DEFINES\", \"DEMONSTRATES\", \"DERIVED_FROM\", \"DIAGNOSES\", \"DIFFERENTIATES\",\n",
    "   \"DISRUPTS\", \"ENHANCES\", \"EVIDENCE_FOR\", \"EXACERBATES\", \"EXPLAINS\",\n",
    "   \"EXPRESSES\", \"FUNCTIONAL_ASSOCIATION\", \"HAS\", \"IMMUNOMODULATES\"]\n",
    "\n",
    "#create text embedder\n",
    "embedder = OpenAIEmbeddings()\n",
    "\n",
    "# define prompt template\n",
    "prompt_template =  \n",
    "You are a medical researcher tasks with extracting information from papers\n",
    "and structuring it in a property graph to inform further medical and research Q&A.\n",
    "\n",
    "Extract the entities (nodes) and specify their type from the following Input text.\n",
    "Also extract the relationships between these nodes. the relationship direction goes from the start node to the end node.\n",
    "\n",
    "\n",
    "Return result as JSON using the following format:\n",
    "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\" }} }}],\n",
    "  \"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
    "\n",
    "...\n",
    "\n",
    "Use only fhe following nodes and relationships:\n",
    "{schema}\n",
    "\n",
    "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
    "Do respect the source and target node types for relationship and the relationship direction.\n",
    "\n",
    "Do not return any additional information other than the JSON in it.\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Input text:\n",
    "\n",
    "{text}\n",
    "\n",
    "# Knowledge Graph Builder\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "\n",
    "kg_builder_pdf = SimpleKGPipeline(\n",
    "   llm=llm,\n",
    "   driver=neo4j_driver,\n",
    "   text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
    "   embedder=embedder,\n",
    "   entities=node_labels,\n",
    "   relations=rel_types,\n",
    "   prompt_template=prompt_template,\n",
    "   from_pdf=True\n",
    ")\n",
    "\n",
    "pdf_file_paths = ['file/1.pdf','file/2.pdf','file/3.pdf','file/4.pdf','file/5.pdf','file/6.pdf','file/7.pdf']\n",
    "\n",
    "for path in pdf_file_paths:\n",
    "    print(f\"Processing : {path}\")\n",
    "    pdf_result = await kg_builder_pdf.run_async(file_path=path)\n",
    "    print(f\"Result: {pdf_result}\")\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def extract_json_fields(file_path):\n",
    "    \"\"\"\n",
    "    Legge un file JSON contenente pagine strutturate e restituisce un nuovo JSON con:\n",
    "        - \"title\": il titolo della pagina,\n",
    "        - \"text\": il testo (se non presente, viene assegnata la stringa vuota),\n",
    "        - \"tables\": le tabelle (se non presente, viene assegnata una lista vuota),\n",
    "        - \"subsections\": le subsezioni (se non presente, viene assegnata una lista vuota),\n",
    "        - \"supersections\": le supersezioni (se non presente, viene assegnata una lista vuota)\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Percorso del file JSON da elaborare.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Un dizionario con le stesse chiavi del JSON originale, ma per ogni pagina sono presenti\n",
    "              solo i campi \"title\", \"text\", \"tables\", \"subsections\" e \"supersections\".\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    result = {}\n",
    "    for key, page in data.items():\n",
    "        title = page.get(\"title\", \"\")\n",
    "        text = page.get(\"text\", \"\")\n",
    "        tables = page.get(\"tables\", [])\n",
    "        subsections = page.get(\"subsections\", [])\n",
    "        supersections = page.get(\"supersections\", [])\n",
    "        result[key] = {\n",
    "            \"title\": title,\n",
    "            \"text\": text,\n",
    "            \"tables\": tables,\n",
    "            \"subsections\": subsections,\n",
    "            \"supersections\": supersections\n",
    "        }\n",
    "    \n",
    "    return result'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
